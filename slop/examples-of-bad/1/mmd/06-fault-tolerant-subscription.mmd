%% Diagram 6: Fault-Tolerant Subscription - Building Resilient Followers
%% Like a bookmark - you never lose your place, even if the book falls
%% Author: As explained by Laurie Voss to a new engineer

flowchart TB
  %% ---- The Happy Path ----
  subgraph HappyPath["âœ… The Happy Path"]
    H_START["ğŸ Start<br/><code>since = load_checkpoint()</code>"]

    H_FETCH{{"ğŸ“¡ Fetch Changes<br/><code>GET /_changes?since={since}</code>"}}

    H_PROCESS["âš™ï¸ Process Batch<br/>Handle each change"]

    H_SAVE["ğŸ’¾ Save Checkpoint<br/><code>since = last_seq</code>"]

    H_MORE{{"More changes?"}}

    H_WAIT["ğŸ˜´ Wait/Long-poll<br/>for new changes"]

    H_START --> H_FETCH
    H_FETCH --> H_PROCESS
    H_PROCESS --> H_SAVE
    H_SAVE --> H_MORE
    H_MORE -->|"Yes"| H_FETCH
    H_MORE -->|"No"| H_WAIT
    H_WAIT --> H_FETCH
  end

  %% ---- Failure Scenarios ----
  subgraph Failures["ğŸš¨ Things That Go Wrong"]
    F1["âš¡ Network Error<br/>'Connection reset'"]
    F2["ğŸ’¥ Process Crash<br/>'Segmentation fault'"]
    F3["ğŸ”„ CouchDB Restart<br/>'503 Service Unavailable'"]
    F4["ğŸ› Processing Error<br/>'JSON parse failed'"]
    F5["ğŸ’¾ Disk Full<br/>'No space left'"]
  end

  %% ---- Recovery Mechanisms ----
  subgraph Recovery["ğŸ›¡ï¸ Recovery Strategies"]
    R1["<b>Network Error Recovery:</b><br/>â€¢ Exponential backoff<br/>â€¢ Start: 1s, Max: 5min<br/>â€¢ Add jitter (Â±30%)<br/>â€¢ Resume from checkpoint"]

    R2["<b>Process Crash Recovery:</b><br/>â€¢ Load last checkpoint<br/>â€¢ Validate checkpoint integrity<br/>â€¢ Resume from safe point"]

    R3["<b>CouchDB 503 Recovery:</b><br/>â€¢ Wait with backoff<br/>â€¢ Monitor /up endpoint<br/>â€¢ Resume when healthy"]

    R4["<b>Processing Error Recovery:</b><br/>â€¢ Log problematic change<br/>â€¢ Skip if non-critical<br/>â€¢ Alert if critical<br/>â€¢ Continue from next"]

    R5["<b>Disk Full Recovery:</b><br/>â€¢ Alert immediately<br/>â€¢ Pause processing<br/>â€¢ Resume after cleanup"]
  end

  %% ---- Connect Failures to Recovery ----
  H_FETCH -.->|"Error"| F1
  H_PROCESS -.->|"Crash"| F2
  H_FETCH -.->|"503"| F3
  H_PROCESS -.->|"Error"| F4
  H_SAVE -.->|"Error"| F5

  F1 --> R1
  F2 --> R2
  F3 --> R3
  F4 --> R4
  F5 --> R5

  R1 --> H_START
  R2 --> H_START
  R3 --> H_WAIT
  R4 --> H_FETCH
  R5 --> H_WAIT

  %% ---- Production Code Pattern ----
  subgraph Code["ğŸ’» Production Code Pattern"]
    CODE["<code>
class ResilientFollower {
  async follow() {
    let since = await loadCheckpoint();
    let retries = 0;

    while (true) {
      try {
        const changes = await fetchChanges(since);

        for (const change of changes.results) {
          await processChange(change);
          since = change.seq;
        }

        await saveCheckpoint(since);
        retries = 0;  // Reset on success

      } catch (error) {
        retries++;
        const delay = Math.min(
          1000 * Math.pow(2, retries),
          300000  // Max 5 minutes
        );

        console.error(`Error: ${error.message}`);
        console.log(`Retry ${retries} in ${delay}ms`);

        await sleep(delay);
      }
    }
  }
}
    </code>"]
  end

  Recovery --> Code

  %% ---- Checkpoint Management ----
  subgraph Checkpoint["ğŸ“ Checkpoint Best Practices"]
    CP1["<b>Atomic Writes:</b><br/><code>
// Write to temp file first
writeFileSync('.checkpoint.tmp', data);
// Then atomic rename
renameSync('.checkpoint.tmp', '.checkpoint');
    </code>"]

    CP2["<b>Include Metadata:</b><br/><code>{
  'seq': '12345-g1AAA...',
  'processed_at': '2024-01-15T10:00:00Z',
  'doc_count': 45678,
  'error_count': 3,
  'hash': 'sha256:abc123...'  // Integrity check
}</code>"]

    CP3["<b>Validation on Load:</b><br/>â€¢ Verify hash matches<br/>â€¢ Check seq is still valid<br/>â€¢ Rewind if corrupted"]
  end

  Code --> Checkpoint

  %% ---- Guarantees ----
  subgraph Guarantees["ğŸ¯ What This Guarantees"]
    G1["âœ… <b>At-least-once delivery</b><br/>May process twice, never miss"]

    G2["âœ… <b>Resumable from any point</b><br/>Even after weeks offline"]

    G3["âœ… <b>Self-healing</b><br/>Recovers from all transient failures"]

    G4["âš ï¸ <b>Requires idempotent processing</b><br/>Same change processed twice = same result"]
  end

  Checkpoint --> Guarantees

  %% ---- Real npm Numbers ----
  subgraph NPMStats["ğŸ“Š npm Registry Scale"]
    NS1["<b>Daily Operations:</b><br/>â€¢ 10,000+ changes/hour peak<br/>â€¢ 99.95% uptime required<br/>â€¢ <1s change propagation"]

    NS2["<b>Failure Frequency:</b><br/>â€¢ Network blips: Daily<br/>â€¢ 503 errors: Weekly<br/>â€¢ Process crashes: Monthly"]

    NS3["<b>Recovery Times:</b><br/>â€¢ Network: 1-30 seconds<br/>â€¢ 503: 30s-5 minutes<br/>â€¢ Crash: <10 seconds"]
  end

  Guarantees --> NPMStats

  %% ---- Styling ----
  classDef happy      fill:#d4edda,stroke:#28a745,stroke-width:2px;
  classDef failure    fill:#f8d7da,stroke:#dc3545,stroke-width:2px;
  classDef recovery   fill:#fff3cd,stroke:#ffc107,stroke-width:2px;
  classDef code       fill:#f5f5f5,stroke:#757575,stroke-width:1px,text-align:left;
  classDef checkpoint fill:#e3f2fd,stroke:#2196f3,stroke-width:2px;
  classDef guarantee  fill:#e1f5e1,stroke:#43a047,stroke-width:2px;
  classDef stats      fill:#e8f5e9,stroke:#4caf50,stroke-width:2px;

  class H_START,H_FETCH,H_PROCESS,H_SAVE,H_MORE,H_WAIT happy;
  class F1,F2,F3,F4,F5 failure;
  class R1,R2,R3,R4,R5 recovery;
  class CODE code;
  class CP1,CP2,CP3 checkpoint;
  class G1,G2,G3,G4 guarantee;
  class NS1,NS2,NS3 stats;